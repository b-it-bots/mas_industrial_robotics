#!/usr/bin/env python3
import os
import random

import numpy as np
import roslib
import rospy
import torch
from cv_bridge import CvBridge, CvBridgeError
from mas_perception_msgs.msg import ImageList, Object, ObjectList
from sensor_msgs.msg import Image, RegionOfInterest
from rgb_object_recognition.yolov7.models.experimental import attempt_load
from rgb_object_recognition.yolov7.utils.datasets import letterbox
from rgb_object_recognition.yolov7.utils.general import check_img_size, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh
from rgb_object_recognition.yolov7.utils.plots import plot_one_box
from rgb_object_recognition.yolov7.utils.torch_utils import select_device, TracedModel, load_classifier, \
    time_synchronized
from ultralytics import YOLO


class RGBObjectRecognizer():
    def __init__(self, weights_1, weights_2, 
                 net='detection', 
                 model_name='yolov8',
                 confidence_threshold=0.8,
                 iou_threshold=0.45,
                 img_size=640,
                 trace=True,
                 classify=False,
                 augment=False,
                 device='cpu',
                 debug_mode=True):
        import sys
        sys.path.insert(0, os.path.join(roslib.packages.get_pkg_dir("mir_object_recognition"),
                           'common', 'src', 'rgb_object_recognition', 'yolov7'))

        self.cvbridge = CvBridge()
        self.debug = debug_mode
        self.pub_debug = rospy.Publisher(
            "/mir_perception/multimodal_object_recognition/recognizer/rgb/output/debug_image", Image, queue_size=1)
        self.pub_result = rospy.Publisher(
            "output/object_list", ObjectList, queue_size=1)
        self.sub_img = rospy.Subscriber(
            "input/images", ImageList, self.image_recognition_cb)
        self.net = net
        self.model_name = model_name
        self.weights_1 = weights_1
        self.weights_2 = weights_2
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.augment = augment

        # Initialize
        self.device = select_device(device)
        self.half = self.device.type != 'cpu'  # half precision only supported on CUDA

        # Load model
        if self.model_name == 'yolov7':
            self.model = attempt_load(self.weights_1, map_location=self.device)  # load FP32 model
            self.names = self.model.module.names if hasattr(self.model, 'module') else self.model.names
            self.colors = [[random.randint(0, 255) for _ in range(3)] for _ in self.names]
            self.stride = int(self.model.stride.max())  # model stride
            img_size = check_img_size(img_size, s=self.stride)  # check img_size
            if trace:
                self.model = TracedModel(self.model, self.device, img_size)

            if self.half:
                self.model.half()  # to FP16

        elif self.model_name == 'yolov8':
            # Load models    
            self.model_atwork = YOLO(self.weights_1)
            self.model_cavity = YOLO(self.weights_2)
        
        self.img_size = img_size

        # Second-stage classifier
        self.classify = classify
        if self.classify:
            self.modelc = load_classifier(name='resnet101', n=2)  # initialize
            self.modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=self.device)['model']).to(
                self.device).eval()

    def image_recognition_cb(self, img_msg):
        if img_msg.images:
            result_list = ObjectList()
            objects = []
            rospy.loginfo("[{}] images received: {} ".format(
                len(img_msg.images), self.model_name))
            if self.net == 'detection':
                try:
                    cv_img = self.cvbridge.imgmsg_to_cv2(
                        img_msg.images[0], "bgr8")

                    if rospy.has_param("/mir_perception/multimodal_object_recognition/obj_category"):
                        obj_category = rospy.get_param("/mir_perception/multimodal_object_recognition/obj_category")
                        if obj_category == "cavity":
                            self.model = self.model_cavity
                        else:
                            self.model = self.model_atwork
                        # print the model name
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using {obj_category} objects category model" + f"\033[0m")
                    else:
                        rospy.loginfo(f"\033[92m" + f"[RGB Recognizer] is using atwork objects category model" + f"\033[0m")

                    if self.model_name == 'yolov7':
                        # Padded resize
                        img = letterbox(cv_img, self.img_size, stride=self.stride)[0]

                        # Convert
                        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
                        img = np.ascontiguousarray(img)
                        old_img_w = old_img_h = self.img_size
                        old_img_b = 1

                        img = torch.from_numpy(img).to(self.device)
                        img = img.half() if self.half else img.float()  # uint8 to fp16/32
                        img /= 255.0  # 0 - 255 to 0.0 - 1.0
                        if img.ndimension() == 3:
                            img = img.unsqueeze(0)

                        # Inference
                        t1 = time_synchronized()
                        pred = self.model(img, augment=self.augment)[0]
                        t2 = time_synchronized()

                        # Apply NMS
                        pred = non_max_suppression(pred, self.confidence_threshold, self.iou_threshold, classes=None,
                                                   agnostic=True)
                        t3 = time_synchronized()

                        # Apply Classifier
                        if self.classify:
                            pred = apply_classifier(pred, self.modelc, img, cv_img)

                        # Process detections
                        bboxes = []
                        probs = []
                        labels = []
                        for i, det in enumerate(pred):  # detections per image
                            gn = torch.tensor(cv_img.shape)[[1, 0, 1, 0]]  # normalization gain whwh
                            if len(det):
                                # Rescale boxes from img_size to im0 size
                                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], cv_img.shape).round()

                                # Write results
                                for *xyxy, conf, cls in reversed(det):
                                    if self.debug:
                                        label = f'{self.names[int(cls)]} {conf:.2f}'
                                        plot_one_box(xyxy, cv_img, label=label, color=self.colors[int(cls)],
                                                     line_thickness=1)
                                    #xywh = (xyxy2xywh(torch.tensor(xyxy).view(-1, 4)) / gn).view(-1).tolist()  # normalized xywh
                                    bboxes.append(xyxy)
                                    probs.append(conf)
                                    labels.append(self.names[int(cls)])
                                if self.debug:
                                    # publish bbox and label
                                    self.publish_debug_img(cv_img)
                        for i in range(len(labels)):
                            result = Object()
                            result.name = labels[i].upper()
                            result.probability = probs[i]
                            roi = RegionOfInterest()
                            roi.x_offset = int(bboxes[i][0])
                            roi.y_offset = int(bboxes[i][1])
                            roi.width = int(bboxes[i][2]) - int(bboxes[i][0])
                            roi.height = int(bboxes[i][3]) - int(bboxes[i][1])
                            result.roi = roi
                            objects.append(result)
                        if self.debug:
                            rospy.logdebug("Detected Objects: %s", labels)

                    elif self.model_name == 'yolov8':

                        predictions = self.model.predict(source=cv_img,
                                                         conf=self.confidence_threshold,
                                                         iou=self.iou_threshold,
                                                         device=self.device,
                                                         verbose=False
                                                        )

                        # convert results to numpy array
                        predictions_np = predictions[0].boxes.numpy()
                        class_ids = predictions_np.cls
                        class_names = predictions[0].names
                        class_labels = [class_names[i] for i in class_ids]
                        class_scores = predictions_np.conf
                        class_bboxes = predictions_np.xyxy # x, y, w, h

                        bboxes, probs, labels = class_bboxes, class_scores, class_labels

                        for i in range(len(labels)):
                            result = Object()
                            result.name = labels[i].upper()
                            result.probability = probs[i]
                            roi = RegionOfInterest()
                            roi.x_offset = int(bboxes[i][0]) # is it center???
                            roi.y_offset = int(bboxes[i][1])
                            roi.width = int(bboxes[i][2] - bboxes[i][0])
                            roi.height = int(bboxes[i][3] - bboxes[i][1])
                            result.roi = roi

                            objects.append(result)
                        # Publish result_list
                        # result_list.objects = objects
                        # self.pub_result.publish(result_list)

                        if self.debug:

                            # Draw bounding boxes and labels of detections
                            debug_img = predictions[0].plot()

                            # publish bbox and label
                            self.publish_debug_img(debug_img)
                    
                    else:
                        bboxes, probs, labels = self.model.classify(cv_img)

                    # Publish result_list
                    result_list.objects = objects
                    self.pub_result.publish(result_list)

                except CvBridgeError as e:
                    rospy.logerr(e)
                    return

            elif self.net == 'classification':
                rospy.logwarn("TODO: MobileNet")

    def publish_debug_img(self, debug_img):
        debug_img = np.array(debug_img, dtype=np.uint8)
        debug_img = self.cvbridge.cv2_to_imgmsg(debug_img, "bgr8")
        self.pub_debug.publish(debug_img)


if __name__ == '__main__':
    rospy.init_node("rgb_object_recognizer")
    rospy.loginfo('Started object recognition node.')
    net = rospy.get_param("~net")
    classifier_name = rospy.get_param("~classifier")
    dataset = rospy.get_param("~dataset")
    model_dir = rospy.get_param("~model_dir")
    model_name_1 = "atwork.pt" # default
    model_name_2 = "cavity.pt"
    weights_1 = os.path.join(roslib.packages.get_pkg_dir("mir_rgb_object_recognition_models"),
                           'common', 'models', classifier_name, dataset, model_name_1)
    weights_2 = os.path.join(roslib.packages.get_pkg_dir("mir_rgb_object_recognition_models"),
                            'common', 'models', classifier_name, dataset, model_name_2)

    object_recognizer = RGBObjectRecognizer(
        weights_1=weights_1, weights_2=weights_2, debug_mode=True)
    rospy.loginfo("\033[92m" + "RGB Recognizer is ready using %s : %s , dataset: %s " + "\033[0m",
              net, classifier_name, dataset)
    rospy.spin()
